{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport json\n\nimport numpy as np \nimport pandas as pd\nimport math\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 10\nplt.rcParams['figure.figsize'] = (15, 5)\nimport seaborn as sns\nfrom PIL import Image\n\nfrom collections import Counter\nfrom collections import defaultdict\n\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import *\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nimport keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T13:18:42.029853Z","iopub.execute_input":"2021-09-29T13:18:42.030149Z","iopub.status.idle":"2021-09-29T13:18:42.054937Z","shell.execute_reply.started":"2021-09-29T13:18:42.030100Z","shell.execute_reply":"2021-09-29T13:18:42.054067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir = \"../input/severstal-steel-defect-detection\"\ntrain_dir = os.path.join(input_dir,\"train_images\")\ntest_dir = os.path.join(input_dir,\"test_images\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T13:18:42.369128Z","iopub.execute_input":"2021-09-29T13:18:42.369434Z","iopub.status.idle":"2021-09-29T13:18:42.374175Z","shell.execute_reply.started":"2021-09-29T13:18:42.369384Z","shell.execute_reply":"2021-09-29T13:18:42.372955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(input_dir, \"train.csv\"))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T13:18:42.723996Z","iopub.execute_input":"2021-09-29T13:18:42.724247Z","iopub.status.idle":"2021-09-29T13:18:42.943338Z","shell.execute_reply.started":"2021-09-29T13:18:42.724189Z","shell.execute_reply":"2021-09-29T13:18:42.942709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['fname'], train_df['cls'] = train_df['ImageId'], train_df['ClassId']\ntrain_df['cls'] = train_df['cls'].astype(int)\ntrain_df = train_df.pivot(index='fname',columns='cls',values='EncodedPixels')\ntrain_df['defects'] = train_df.count(axis=1)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T13:18:43.139215Z","iopub.execute_input":"2021-09-29T13:18:43.139487Z","iopub.status.idle":"2021-09-29T13:18:43.170678Z","shell.execute_reply.started":"2021-09-29T13:18:43.139439Z","shell.execute_reply":"2021-09-29T13:18:43.169595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Presence of defects in each images\nno_defects_num = np.sum(train_df['defects'] == 0)\ndefects_num = len(train_df) - no_defects_num\nprint(\"no_defect imgs \\t:\", no_defects_num)\nprint(\"defects imgs \\t:\", defects_num)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:39.178776Z","iopub.execute_input":"2021-09-29T12:42:39.179062Z","iopub.status.idle":"2021-09-29T12:42:39.185704Z","shell.execute_reply.started":"2021-09-29T12:42:39.179010Z","shell.execute_reply":"2021-09-29T12:42:39.184742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of defects for each class\nclass_defects = len(train_df) - train_df.isnull().sum() \nclass_defects","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:40.308181Z","iopub.execute_input":"2021-09-29T12:42:40.308545Z","iopub.status.idle":"2021-09-29T12:42:40.320403Z","shell.execute_reply.started":"2021-09-29T12:42:40.308489Z","shell.execute_reply":"2021-09-29T12:42:40.319128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls = [1, 2, 3, 4]\nno_of_defects = []\n\nfor i in range(1, len(class_defects)):\n    no_of_defects.append(class_defects[i])\n    \nfig, ax = plt.subplots()\nsns.barplot(x=cls , y=no_of_defects , ax=ax)\nax.set_title(\"the number of images for each class\")\nax.set_xlabel(\"class\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:48.070729Z","iopub.execute_input":"2021-09-29T12:42:48.071028Z","iopub.status.idle":"2021-09-29T12:42:48.327267Z","shell.execute_reply.started":"2021-09-29T12:42:48.070976Z","shell.execute_reply":"2021-09-29T12:42:48.326420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palet = [(250, 230, 20), (30, 200, 241), (200, 30, 250), (250,60,20)]\n\nfig, ax = plt.subplots(1, 4, figsize=(6, 2))\nfor i in range(4):\n    ax[i].axis('off')\n    ax[i].imshow(np.ones((20, 80, 3), dtype=np.uint8) * palet[i])\n    ax[i].set_title(f\"class{i+1}\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:51.979307Z","iopub.execute_input":"2021-09-29T12:42:51.979599Z","iopub.status.idle":"2021-09-29T12:42:52.187605Z","shell.execute_reply.started":"2021-09-29T12:42:51.979549Z","shell.execute_reply":"2021-09-29T12:42:52.186841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask2rgba(mask):\n    rgba_list = []\n    for idx in range(4):     # idx: class id\n        rgba = cv2.cvtColor(mask[:, :, idx], cv2.COLOR_GRAY2RGBA)\n        rgba[:, :, :3] = rgba[:, :, :3] /255 * palet[idx]\n        rgba_list.append(rgba)\n    return rgba_list","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:53.009891Z","iopub.execute_input":"2021-09-29T12:42:53.010177Z","iopub.status.idle":"2021-09-29T12:42:53.017108Z","shell.execute_reply.started":"2021-09-29T12:42:53.010128Z","shell.execute_reply":"2021-09-29T12:42:53.016182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createMask(row_id):\n    \"\"\"\n    row_id: index corresponding to image name in train_df; say for row_id = 1\n    imgId: 0007a71bf.jpg\n    en_pixels =   cls\n                1                                                  NaN\n                2                                                  NaN\n                3    18661 28 18863 82 19091 110 19347 110 19603 11...\n                4                                                  NaN\n    en_pixels.values = array([nan, nan, '18661 28 18863 82 19091 110 19347 110 19603 11...', nan]\n    \"\"\"\n    imgId = train_df.iloc[row_id].name  \n\n    en_pixels = train_df.iloc[row_id][:4]\n    masks = np.zeros((256, 1600, 4), dtype=np.uint8)     # 4 channels corresponding to the 4 defects\n\n    for idx, en_pix in enumerate(en_pixels.values):\n        if en_pix is not np.nan:\n            en_pix = en_pix.split(\" \")\n            pixel_start = map(int, en_pix[0::2])\n            pixel_length = map(int, en_pix[1::2])\n            mask = np.zeros(256 * 1600, dtype=np.uint8)\n            for start, length in zip(pixel_start, pixel_length):\n                mask[start:(start + length)] = 255\n            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n            \n    return imgId, masks","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:53.999518Z","iopub.execute_input":"2021-09-29T12:42:53.999937Z","iopub.status.idle":"2021-09-29T12:42:54.009334Z","shell.execute_reply.started":"2021-09-29T12:42:53.999870Z","shell.execute_reply":"2021-09-29T12:42:54.008376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def showMasks(row_id, contour = True):\n    imgId, mask = createMask(row_id)\n    img = cv2.imread(os.path.join(train_dir, imgId))\n\n    if contour:\n        for ch in range(4):\n            contours, _ = cv2.findContours(mask[:, :, ch],\n                            cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n            for i in range(0, len(contours)):\n                cv2.polylines(img, contours[i], True, palet[ch], 2)\n    else:\n        for ch in range(4):\n            img[mask[:,:,ch]==255] = palet[ch]\n        \n    fig, ax = plt.subplots(figsize=(12,12))\n    ax.set_title(imgId)\n    ax.imshow(img)\n    ax.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:54.890670Z","iopub.execute_input":"2021-09-29T12:42:54.890973Z","iopub.status.idle":"2021-09-29T12:42:54.900078Z","shell.execute_reply.started":"2021-09-29T12:42:54.890925Z","shell.execute_reply":"2021-09-29T12:42:54.899336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# anonymous lambda function syntax - lambda arguments: expression\n# classify defects\nidx_class_1 = list(filter(lambda r:not pd.isna(train_df.iloc[r,0]), range(len(train_df))))\nidx_class_2 = list(filter(lambda r:not pd.isna(train_df.iloc[r,1]), range(len(train_df))))\nidx_class_3 = list(filter(lambda r:not pd.isna(train_df.iloc[r,2]), range(len(train_df))))\nidx_class_4 = list(filter(lambda r:not pd.isna(train_df.iloc[r,3]), range(len(train_df))))\n\n# Number of defects class\nidx_1_defect = list(filter(lambda r:train_df.iloc[r,4] == 1, range(len(train_df))))\nidx_class_multi = list(filter(lambda r:train_df.iloc[r,4] >= 2, range(len(train_df))))","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:55.708134Z","iopub.execute_input":"2021-09-29T12:42:55.708437Z","iopub.status.idle":"2021-09-29T12:42:56.227717Z","shell.execute_reply.started":"2021-09-29T12:42:55.708386Z","shell.execute_reply":"2021-09-29T12:42:56.226914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_1 defect sumple (Yellow)\nfor idx in idx_class_1[-3:]:\n    showMasks(idx, contour=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:56.487813Z","iopub.execute_input":"2021-09-29T12:42:56.488067Z","iopub.status.idle":"2021-09-29T12:42:57.055105Z","shell.execute_reply.started":"2021-09-29T12:42:56.488022Z","shell.execute_reply":"2021-09-29T12:42:57.054054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_2 defect sumple (lightblue)\nfor idx in idx_class_2[-3:]:\n    showMasks(idx, contour=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:57.278545Z","iopub.execute_input":"2021-09-29T12:42:57.278867Z","iopub.status.idle":"2021-09-29T12:42:57.923207Z","shell.execute_reply.started":"2021-09-29T12:42:57.278811Z","shell.execute_reply":"2021-09-29T12:42:57.922388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_3 defect sumple (purple)\nfor idx in idx_class_3[-3:]:\n    showMasks(idx, contour=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:57.924977Z","iopub.execute_input":"2021-09-29T12:42:57.925473Z","iopub.status.idle":"2021-09-29T12:42:58.565368Z","shell.execute_reply.started":"2021-09-29T12:42:57.925423Z","shell.execute_reply":"2021-09-29T12:42:58.564676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_4 defect sumple (red)\nfor idx in idx_class_4[-3:]:\n    showMasks(idx, contour=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:58.567046Z","iopub.execute_input":"2021-09-29T12:42:58.567576Z","iopub.status.idle":"2021-09-29T12:42:59.220728Z","shell.execute_reply.started":"2021-09-29T12:42:58.567522Z","shell.execute_reply":"2021-09-29T12:42:59.219987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# contain multi class defects\nfor idx in idx_class_multi[-3:]:\n    showMasks(idx, contour=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:42:59.399072Z","iopub.execute_input":"2021-09-29T12:42:59.399320Z","iopub.status.idle":"2021-09-29T12:42:59.999804Z","shell.execute_reply.started":"2021-09-29T12:42:59.399275Z","shell.execute_reply":"2021-09-29T12:42:59.998953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataGenerator(ids, batch_size):\n    Xs = []; ys = []\n    while True:\n        for i in ids:\n            imgId, masks = createMask(i)\n            img = cv2.imread(os.path.join(train_dir, imgId), cv2.IMREAD_GRAYSCALE)\n            img = img[..., np.newaxis]   # Add channel axis\n            img = img / 255.             # 0～1\n            masks = masks / 255.         # 0～1\n            Xs.append(img); ys.append(masks)\n            if len(Xs) == batch_size:\n                X = np.array(Xs); y = np.array(ys)\n                Xs = []; ys = []\n                yield [X, y]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:08:27.852729Z","iopub.execute_input":"2021-09-29T10:08:27.853028Z","iopub.status.idle":"2021-09-29T10:08:27.863307Z","shell.execute_reply.started":"2021-09-29T10:08:27.852977Z","shell.execute_reply":"2021-09-29T10:08:27.862436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation Model","metadata":{}},{"cell_type":"code","source":"##### Training conditions ##### \nbatch_size = 16\nepochs = 50\nsteps_per_epoch = 200","metadata":{"execution":{"iopub.status.busy":"2021-09-29T09:25:17.639842Z","iopub.execute_input":"2021-09-29T09:25:17.640311Z","iopub.status.idle":"2021-09-29T09:25:17.646908Z","shell.execute_reply.started":"2021-09-29T09:25:17.640119Z","shell.execute_reply":"2021-09-29T09:25:17.645753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# U-Net\n\ninput_shape = (256, 1600, 1)\ninputs = Input(input_shape)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\np5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\nc55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\nc55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\nu6 = concatenate([u6, c5])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu71 = concatenate([u71, c4])\nc71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\nc61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:31:22.112932Z","iopub.execute_input":"2021-06-14T18:31:22.11323Z","iopub.status.idle":"2021-06-14T18:31:22.659204Z","shell.execute_reply.started":"2021-06-14T18:31:22.113174Z","shell.execute_reply":"2021-06-14T18:31:22.65819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    '''\n    This function returns dice coefficient of similarity between y_true and y_pred\n    Dice coefficient is also referred to as F1_score, but we will use this name for image segmentation models\n    For example, \n    let an instance on y_true and y_pred be [[1,1],[0,1]] and [[1,0],[0,1]]\n    this metric first converts the above into [1,1,0,1] abd [1,0,0,1],\n    then intersection is calculated as 1*1 + 1*0 + 0*1 + 1*1 = 2 and sum(y_true)+sum(y_pred)= 3+2 = 5\n    this returns the value (2.* 2 + 10e-7)/(3 + 2 + 10e-7) ~ 0.8    \n    '''\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \\ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:31:23.949894Z","iopub.execute_input":"2021-06-14T18:31:23.950204Z","iopub.status.idle":"2021-06-14T18:31:23.958271Z","shell.execute_reply.started":"2021-06-14T18:31:23.950152Z","shell.execute_reply":"2021-06-14T18:31:23.957552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam()\nmodel.compile(optimizer, 'binary_crossentropy', metrics=[dice_coef])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:31:35.206689Z","iopub.execute_input":"2021-06-14T18:31:35.207014Z","iopub.status.idle":"2021-06-14T18:31:35.264289Z","shell.execute_reply.started":"2021-06-14T18:31:35.206951Z","shell.execute_reply":"2021-06-14T18:31:35.263404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids, val_ids = train_test_split(range(len(train_df)), test_size=0.15)\ntrain_gen = dataGenerator(train_ids, batch_size)\nval_gen = dataGenerator(val_ids, batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:34:47.075716Z","iopub.execute_input":"2021-06-14T18:34:47.076025Z","iopub.status.idle":"2021-06-14T18:34:47.085084Z","shell.execute_reply.started":"2021-06-14T18:34:47.075974Z","shell.execute_reply":"2021-06-14T18:34:47.08429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator test\nfor X, y in dataGenerator(range(len(train_df)), 4):\n    break\n\nprint('X.shape:',X.shape, '\\ny.shape:',y.shape)\n\nrow = 0\nshowMasks(row, contour=True)\n\nfig, axs = plt.subplots(5, figsize=(12,12))\naxs[0].imshow(X[row,:,:,0])\naxs[0].axis('off')\naxs[0].set_title(train_df.iloc[row].name)\nfor i in range(4):\n    axs[i+1].imshow(y[row,:,:,i])\n    axs[i+1].set_title(f\"defect {i+1}\")\n    axs[i+1].axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:35:01.250201Z","iopub.execute_input":"2021-06-14T18:35:01.250491Z","iopub.status.idle":"2021-06-14T18:35:02.271328Z","shell.execute_reply.started":"2021-06-14T18:35:01.250441Z","shell.execute_reply":"2021-06-14T18:35:02.270673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callback\ncheckpoint = ModelCheckpoint(\"DefectDetection.h5\", monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:36:09.447347Z","iopub.execute_input":"2021-06-14T18:36:09.447638Z","iopub.status.idle":"2021-06-14T18:36:09.452617Z","shell.execute_reply.started":"2021-06-14T18:36:09.44759Z","shell.execute_reply":"2021-06-14T18:36:09.451559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_gen,\n                              steps_per_epoch=steps_per_epoch,\n                              epochs=epochs,\n                              validation_data=val_gen,\n                              validation_steps = len(val_ids)//batch_size,\n                              verbose=2,\n                              shuffle=True,\n                              callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:36:22.474715Z","iopub.execute_input":"2021-06-14T18:36:22.475035Z","iopub.status.idle":"2021-06-14T18:39:14.897909Z","shell.execute_reply.started":"2021-06-14T18:36:22.474972Z","shell.execute_reply":"2021-06-14T18:39:14.896709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot\nfig, ax = plt.subplots(1,2,figsize=(15, 8))\n\nax[0].plot(hist_df['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist_df['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist_df['dice_coef'], color='b', label=\"Training dice_coef\")\nax[1].plot(hist_df['val_dice_coef'], color='r',label=\"Validation dice_coef\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Binarize the mask output by NN\ndef binarize(masks, th = 0.5):\n    # Maximum value of each channel per pixel\n    mask_max = np.zeros_like(masks[:,:,0])\n    mask_max = np.fmax(masks[:,:,0], masks[:,:,1])\n    mask_max = np.fmax(mask_max,masks[:,:,2])\n    mask_max = np.fmax(mask_max,masks[:,:,3])\n    # Remove non-maximum pixels\n    m = np.zeros_like(masks)\n    for ch in range(4):\n        m[:,:,ch] = (masks[:,:,ch] == mask_max) * masks[:,:,ch]\n        \n    # Binarization\n    m = (m>th) * 1\n    return m","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predict_img(df, row):\n    if df == \"train_df\":\n        name = train_df.iloc[row].name\n        img = cv2.imread(os.path.join(DIRtrain, name),\n                             cv2.IMREAD_GRAYSCALE)\n    else:\n        if df == \"submit_df\":\n            name = test_df.iloc[row//4,0].split('_')[0]\n        elif df == \"test_df\":\n            name = test_df.iloc[row,0]\n        img = cv2.imread(os.path.join(DIRtest, name),\n                             cv2.IMREAD_GRAYSCALE)\n\n    img_ = img[..., np.newaxis]    # Add channel axis\n    img_ = img_[np.newaxis, ...]    # Add batch axis\n    img_ = img_ / 255.              # 0～1\n\n    pred_masks = model.predict(img_)\n    bin_masks = binarize(pred_masks[0, ...], 0.5)\n    \n    fig, axs = plt.subplots(5,2, figsize=(12, 6))\n    axs[0,0].imshow(img)\n    axs[0,0].axis('off')\n    axs[0,0].set_title(name)\n    axs[0,1].axis('off')\n    axs[0,1].set_title(\"after binarize\")\n    for i in range(4):\n        axs[i+1,0].imshow(pred_masks[0,:,:,i])\n        axs[i+1,0].axis('off')\n        axs[i+1,0].set_title('class '+ str(i+1))\n        axs[i+1,1].imshow(bin_masks[:,:,i])\n        axs[i+1,1].axis('off')\n        axs[i+1,1].set_title('class '+ str(i+1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_pred_and_target_mask(idx): # idx - индекс фото\n    name = train_df.iloc[idx].name\n    img = cv2.imread(os.path.join(DIRtrain, name),\n                         cv2.IMREAD_GRAYSCALE)\n    name, mask = make_mask(idx) # true mask\n\n    img_ = img[..., np.newaxis]    # Add channel axis\n    img_ = img_[np.newaxis, ...]    # Add batch axis\n    img_ = img_ / 255.              # 0～1\n    mask = mask / 255.\n    pred_masks = model.predict(img_)\n    bin_masks = binarize(pred_masks[0, ...], 0.5)\n    \n    show_mask_image(idx, contour=True)\n    fig, axs = plt.subplots(4,2, figsize=(12, 6))\n\n    for i in range(4):\n        axs[i,0].imshow(mask[:,:,i])\n        axs[i,0].axis('off')\n        axs[i,0].set_title('Groundtruth class '+ str(i+1))\n        axs[i,1].imshow(bin_masks[:,:,i])\n        axs[i,1].axis('off')\n        axs[i,1].set_title('Predicted class '+ str(i+1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict sample\nstart_index, end_index = 1, 5\nfor i in range(start_index, end_index):\n#     show_mask_image(i, contour=True)\n#     show_predict_img(\"train_df\", i)\n    plot_pred_and_target_mask(i)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# COMPETITION METRIC \n\n# Custom metrics, https://stackoverflow.com/questions/59196793/why-are-my-metrics-of-my-cnn-not-changing-with-each-epoch\ndef recall_m(y_true, y_pred):\n    '''\n    This function returns recall_score between y_true and y_pred\n    This function is ported as a metric to the Neural Network Models\n    Keras backend is used to take care of batch type training, the metric takes in a batch of y_pred and corresponding y_pred \n    as input and returns recall score of the batch\n    '''\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # calculates number of true positives\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))      # calculates number of actual positives\n    recall = true_positives / (possible_positives + K.epsilon())   # K.epsilon takes care of non-zero divisions\n    return recall\n\ndef precision_m(y_true, y_pred):\n    '''\n    This function returns precison_score between y_true and y_pred\n    This function is ported as a metric to the Neural Network Models\n    Keras backend is used to take care of batch type training, the metric takes in a batch of y_pred and corresponding y_pred \n    as input and returns prediction score of the batch\n    '''\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # calculates number of true positives\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))      # calculates number of predicted positives   \n    precision = true_positives /(predicted_positives + K.epsilon()) # K.epsilon takes care of non-zero divisions\n    return precision\n    \ndef f1_score_m(y_true, y_pred):\n    '''\n    This function returns f1_score between y_true and y_pred\n    This \n    This function is ported as a metric to the Neural Network Models\n    Keras backend is used to take care of batch type training, the metric takes in a batch of y_pred and corresponding y_pred \n    as input and returns f1 score of the batch\n    '''\n    precision = precision_m(y_true, y_pred)  # calls precision metric and takes the score of precision of the batch\n    recall = recall_m(y_true, y_pred)        # calls recall metric and takes the score of precision of the batch\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n\ndef area(i):\n    '''\n    Input: EncodedPixels (str)\n    Output: number of pixels having the defect\n    '''\n    return sum([int(k) for k in i.split(' ')[1::2]])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}